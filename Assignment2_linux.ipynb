{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3f41f08508a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmasks_sorted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmasks_paths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mim_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_sorted\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m45\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#import data \n",
    "\n",
    "import pathlib\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "# Glob the training data and load a single image path\n",
    "training_paths = pathlib.Path('/modules/cs342/Assignment2/FullTraining').glob('*/images/*.png')\n",
    "training_sorted = sorted([x for x in training_paths])\n",
    "\n",
    "masks_paths = pathlib.Path('/modules/cs342/Assignment2/FullTraining').glob('*/masks/*.png')\n",
    "masks_sorted = sorted([x for x in masks_paths])\n",
    "\n",
    "im_path = training_sorted[45]\n",
    "im = imageio.imread(str(im_path))\n",
    "\n",
    "print len(masks_sorted)\n",
    "im_path2 = masks_sorted[45]\n",
    "im2 = imageio.imread(str(im_path2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.color import rgb2gray\n",
    "im_gray = rgb2gray(im)\n",
    "plt.imshow(im_gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<large>HoG</large>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "\n",
    "fd,hog_image = hog(im_gray, orientations=16, pixels_per_cell=(2, 2),cells_per_block=(3, 3),visualise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(hog_image,cmap='gray', interpolation='nearest');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "winSize = (32,32)\n",
    "blockSize = (32,32)\n",
    "blockStride = (2,2)\n",
    "cellSize = (2,2)\n",
    "nbins = 9\n",
    "\n",
    "hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins)\n",
    "hist = hog.compute(im\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It looks like hog is not very well suited for this kind of problem. Anyway just say in the report not very useful for our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<large>Otsu threshold + watershed</large>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#code taken from kernel\n",
    "\n",
    "from skimage.filters import threshold_otsu\n",
    "thresh_val = threshold_otsu(im_gray)\n",
    "mask = np.where(im_gray > thresh_val, 1, 0)\n",
    "\n",
    "# Make sure the larger portion of the mask is considered background\n",
    "if np.sum(mask==0) < np.sum(mask==1):\n",
    "    mask = np.where(mask, 0, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "labels, nlabels = ndimage.label(mask)\n",
    "\n",
    "label_arrays = []\n",
    "for label_num in range(1, nlabels+1):\n",
    "    label_mask = np.where(labels == label_num, 1, 0)\n",
    "    label_arrays.append(label_mask)\n",
    "\n",
    "print('There are {} separate components / objects detected.'.format(nlabels))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(label_arrays[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a random colormap\n",
    "from matplotlib.colors import ListedColormap\n",
    "rand_cmap = ListedColormap(np.random.rand(256,3))\n",
    "\n",
    "labels_for_display = np.where(labels > 0, labels, np.nan)\n",
    "plt.imshow(im_gray, cmap='gray')\n",
    "plt.imshow(labels_for_display, cmap=rand_cmap)\n",
    "plt.axis('off')\n",
    "plt.title('Labeled Cells ({} Nuclei)'.format(nlabels))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for label_ind, label_coords in enumerate(ndimage.find_objects(labels)):\n",
    "    cell = im_gray[label_coords]\n",
    "    \n",
    "    # Check if the label size is too small\n",
    "    if np.product(cell.shape) < 10: \n",
    "        print('Label {} is too small! Setting to 0.'.format(label_ind))\n",
    "        mask = np.where(labels==label_ind+1, 0, mask)\n",
    "\n",
    "# Regenerate the labels\n",
    "labels, nlabels = ndimage.label(mask)\n",
    "print('There are now {} separate components / objects detected.'.format(nlabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "image=labels\n",
    "\n",
    "# Now we want to separate the two objects in image\n",
    "# Generate the markers as local maxima of the distance to the background\n",
    "distance = ndi.distance_transform_edt(image)\n",
    "local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((3, 3)),\n",
    "                            labels=image)\n",
    "markers = ndi.label(local_maxi)[0]\n",
    "labels = watershed(-distance, markers, mask=image)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(9, 3), sharex=True, sharey=True,\n",
    "                         subplot_kw={'adjustable': 'box-forced'})\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(image, cmap=plt.cm.gray, interpolation='nearest')\n",
    "ax[0].set_title('Overlapping objects')\n",
    "ax[1].imshow(-distance, cmap=plt.cm.gray, interpolation='nearest')\n",
    "ax[1].set_title('Distances')\n",
    "ax[2].imshow(labels, cmap=plt.cm.spectral, interpolation='nearest')\n",
    "ax[2].set_title('Separated objects')\n",
    "\n",
    "for a in ax:\n",
    "    a.set_axis_off()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From the above we can see that we can also do watershed but it doesn't look very good, a lot of nuclei are further split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "train_labels = pd.read_csv(os.path.join('/modules/cs342/Assignment2/FullTraining','{}_train_labels.csv'.format('stage1')))\n",
    "train_labels['EncodedPixels'] = train_labels['EncodedPixels'].map(lambda ep: [int(x) for x in ep.split(' ')])\n",
    "train_labels.head(27)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels['EncodedPixels'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to rewrite all the part above, but for the moment not important.\n",
    "Now we focus on the second part. Try to use MLP. But to do this we first need to scale all pictures to the same.\n",
    "We try to using code from: https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "from skimage.transform import resize\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 4\n",
    "TRAIN_PATH = '/modules/cs342/Assignment2/FullTraining'\n",
    "TEST_PATH = '../input/stage1_test/'\n",
    "\n",
    "\n",
    "scaled_pictures = np.zeros((len(training_sorted), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "for n,im_path in enumerate(training_sorted):\n",
    "    im = imageio.imread(str(im_path))\n",
    "    im = resize(im, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    scaled_pictures[n]= im\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    for mask_file in masks_sorted:\n",
    "        mask\n",
    "        \n",
    "    \n",
    "    \n",
    "scaled_masks = np.zeros((len(test_sorted), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "\n",
    "for n,im_path in enumerate(training_sorted):\n",
    "    im = imageio.imread(str(im_path))\n",
    "    im = resize(im, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    scaled_pictures[n]= im\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "# Set some parameters\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_PATH = '/modules/cs342/Assignment2/FullTraining/'\n",
    "TEST_PATH = '/modules/cs342/Assignment2/FullTesting/'\n",
    "\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]\n",
    "\n",
    "\n",
    "# Get and resize train images and masks\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask\n",
    "\n",
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(Y_train[10][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(X_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(Y_train[23]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pixels = Y_train[10].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_pixels= []\n",
    "for picture in X_train:\n",
    "    X_train_pixels.append(picture.flatten())\n",
    "X_train_pixels= np.asarray(X_train_pixels)    \n",
    "    \n",
    "   \n",
    "Y_train_pixels= []\n",
    "for picture in Y_train:\n",
    "    Y_train_pixels.append(picture.flatten())\n",
    "Y_train_pixels= np.asarray(Y_train_pixels)  \n",
    "    \n",
    "X_test_pixels= []\n",
    "for picture in X_test:\n",
    "    X_test_pixels.append(picture.flatten()) \n",
    "X_test_pixels= np.asarray(X_test_pixels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(X_test_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))\n",
    "mlp.fit(X_train_pixels,Y_train_pixels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(Y_train_pixels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = mlp.predict(X_train_pixels[6])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=a.reshape((128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b =X_test_pixels[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b.reshape((128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda2]",
   "language": "python",
   "name": "Python [Anaconda2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
